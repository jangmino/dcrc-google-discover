{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다이나믹스를 반영한 메트릭 분석: 김미령"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager\n",
    "from matplotlib import rc\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "f_path = '/Library/Fonts/Arial Unicode.ttf'\n",
    "font_manager.FontProperties(fname=f_path).get_name()\n",
    "\n",
    "rc('font', family='Arial Unicode MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from networkx.algorithms import bipartite, community\n",
    "from networkx.algorithms.community import modularity, louvain_communities\n",
    "import matplotlib.colors as mcolors\n",
    "from collections import Counter\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../local_data/dynamics_attached_sheet.pkl', 'rb') as file:\n",
    "with open('../local_data/dynamics_attached_sheet_20241102.pkl', 'rb') as file:\n",
    "    result_based_on_today = pickle.load(file)\n",
    "    result_based_on_yesterday = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testers = list(result_based_on_today.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 엑셀 시트로 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_dict_to_excel(data_dict, excel_file_path):\n",
    "#     # ExcelWriter 객체 생성\n",
    "#     with pd.ExcelWriter(excel_file_path, engine=None) as writer:\n",
    "#         # 딕셔너리의 각 항목에 대해 반복\n",
    "#         for sheet_name, df in data_dict.items():\n",
    "#             # 데이터프레임을 엑셀 시트로 저장\n",
    "#             df.to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dict_to_excel(result_based_on_today, '../local_data/dynamics-and-category-assigned-results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = testers[0]\n",
    "tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_daily_mean_adjusted_df(source_df:pd.DataFrame, tester):\n",
    "    '''\n",
    "    trial_idx 별 평균을 구한 후, 이를 뺀 값으로 보정한 메트릭을 추가함\n",
    "    *_adjusted로 추가함\n",
    "    trial_idx > 0 인 경우에만 계산함\n",
    "    '''\n",
    "    df = source_df[tester].query('trial_idx > 0').copy()\n",
    "    df['trial_pos'] = df.groupby('trial_idx').cumcount()\n",
    "\n",
    "    # Calculate the mean for each trial_idx for precision, freshness, and satisfaction\n",
    "    trial_idx_means = df.groupby('trial_idx')[['precision', 'freshness', 'satisfaction']].mean()\n",
    "\n",
    "    # Merge the mean values back to the original dataset\n",
    "    df = df.merge(trial_idx_means, on='trial_idx', suffixes=('', '_mean'))\n",
    "\n",
    "    # Calculate the adjusted values by subtracting the mean values from the original values\n",
    "    df['precision_adjusted'] = df['precision'] - df['precision_mean']\n",
    "    df['freshness_adjusted'] = df['freshness'] - df['freshness_mean']\n",
    "    df['satisfaction_adjusted'] = df['satisfaction'] - df['satisfaction_mean']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = make_daily_mean_adjusted_df(result_based_on_today, tester)\n",
    "disappearing_df = make_daily_mean_adjusted_df(result_based_on_yesterday, tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_cols = ['precision', 'freshness', 'satisfaction']\n",
    "metric_cols_adjusted = [col + '_adjusted' for col in metric_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 기본 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate global averages for precision, freshness, satisfaction\n",
    "global_averages = df[metric_cols].mean()\n",
    "# daily_averages = df[['precision', 'freshness', 'satisfaction']].mean()\n",
    "\n",
    "# Step 2: Calculate averages per trial_idx and trial_pos\n",
    "trial_idx_averages = df.groupby('trial_idx')[metric_cols].mean()\n",
    "trial_pos_averages = df.groupby('trial_pos')[metric_cols].mean()\n",
    "\n",
    "# Compare these with the global averages\n",
    "trial_idx_differences = trial_idx_averages - global_averages\n",
    "trial_pos_differences = trial_pos_averages - global_averages\n",
    "\n",
    "# import ace_tools as tools; tools.display_dataframe_to_user(name=\"Trial Index Differences\", dataframe=trial_idx_differences)\n",
    "# tools.display_dataframe_to_user(name=\"Trial Position Differences\", dataframe=trial_pos_differences)\n",
    "\n",
    "# trial_idx_differences, trial_pos_differences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`trial_idx` 기준으로 각 메트릭과 전역 평균값과의 차이 플로팅\n",
    "\n",
    "- 날짜가 지날 수록 감소함\n",
    "- 시행 초기에 메트릭이 높으나 점차 감소하여 마이너스가 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_idx_differences.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`trial_pos` 기준으로 각 메트릭과 전역 평균값과의 차이 플로팅\n",
    "\n",
    "- 확연한 차이는 아니지만 상위 위치에서 메트릭이 양수가 많음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_pos_differences.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 (*) 일평균을 뺀 것으로 보정하여 분석 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate global averages for precision, freshness, satisfaction\n",
    "global_averages = df[metric_cols_adjusted].mean()\n",
    "# daily_averages = df[['precision', 'freshness', 'satisfaction']].mean()\n",
    "\n",
    "# Step 2: Calculate averages per trial_idx and trial_pos\n",
    "trial_idx_averages = df.groupby('trial_idx')[metric_cols_adjusted].mean()\n",
    "trial_pos_averages = df.groupby('trial_pos')[metric_cols_adjusted].mean()\n",
    "\n",
    "# Compare these with the global averages\n",
    "trial_idx_differences = trial_idx_averages\n",
    "trial_pos_differences = trial_pos_averages\n",
    "\n",
    "# import ace_tools as tools; tools.display_dataframe_to_user(name=\"Trial Index Differences\", dataframe=trial_idx_differences)\n",
    "# tools.display_dataframe_to_user(name=\"Trial Position Differences\", dataframe=trial_pos_differences)\n",
    "\n",
    "# trial_idx_differences, trial_pos_differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_idx_differences.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_pos_differences.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 노드 타입에 따른 메트릭 차이 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with NaN values in 'type' to focus on rows where type is defined\n",
    "filtered_data = df.dropna(subset=['type'])\n",
    "\n",
    "# Step 1: Calculate averages per node type\n",
    "type_averages = \\\n",
    "    pd.concat((filtered_data.groupby('type')[metric_cols_adjusted].mean(),\n",
    "        disappearing_df.groupby('type')[metric_cols_adjusted].mean()), axis=0)\n",
    "\n",
    "# relative_type_averages = type_averages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "절대값 플로팅과 상대 차이 플로팅\n",
    "\n",
    "- 노드 타입에 따라 precision, freshness, satisfaction에 차이 확인.\n",
    "- `merging`과 `shrinking` 타입에서 상대적으로 높은 satisfaction 점수가 보임\n",
    "- 반대로 `persisting` 타입에서는 비교적 낮은 점수가 나타남\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_averages.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join([x[:2].upper() for x in type_averages.sort_values('satisfaction_adjusted', ascending=False).index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 persisting 노드의 유지 기간에 따른 메트릭 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for 'persisting' type nodes and those that have a non-null streak_count\n",
    "persisting_data = filtered_data[filtered_data['type'] == 'persisting'].dropna(subset=['streak_count'])\n",
    "\n",
    "# Step 1: Calculate averages based on streak_count\n",
    "streak_count_averages = persisting_data.groupby('streak_count')[metric_cols_adjusted].mean()\n",
    "\n",
    "# streak_count_averages\n",
    "\n",
    "# relative_streak_count_averages = streak_count_averages - global_averages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "플로팅을 통한 확인\n",
    "\n",
    "- 유지 기간이 길수록 메트릭 감소가 확연함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streak_count_averages.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 주요 결과와 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 평가 지표(precision, freshness, satisfaction)에 대한 글로벌 평균 대비 분석\n",
    "- `trial_idx`와 평가 값의 관계:\n",
    "    - `trial_idx` 0번에서 글로벌 평균보다 높은 precision, freshness, satisfaction 점수를 기록\n",
    "    - 이는 첫 날 노출된 콘텐츠들이 전반적으로 사용자들로부터 긍정적인 평가를 받았음을 시사\n",
    "    - `trial_idx` 가 증가함에 따라 평가 점수는 점차 글로벌 평균에 근접하거나 감소하는 경향을 보임\n",
    "- `trial_pos`와 평가 값의 관계:\n",
    "    - `trial_pos` 상위(0~2번)에 위치한 콘텐츠들이 전반적으로 글로벌 평균보다 높은 평가 점수를 받음\n",
    "    - 이는 사용자가 처음 노출되는 콘텐츠에 더 높은 만족도를 느끼는 경향이 있음에 대한 가능성\n",
    "2. 노드 타입에 따른 평가 지표의 차이\n",
    "- 노드 타입별 차이:\n",
    "    - `merging`과 `shrinking` 노드 타입은 다른 타입에 비해 상대적으로 높은 satisfaction 점수를 기록\n",
    "    - 이는 이러한 노드들이 사용자들에게 더 긍정적인 경험을 제공했음을 시사\n",
    "    - 반면, `persisting`` 노드는 전체적으로 낮은 평가 점수를 기록\n",
    "    - 이는 동일한 콘텐츠가 반복적으로 노출되는 것에 대해 사용자가 피로감을 느끼거나 흥미를 잃었을 가능성을 시사\n",
    "3. `persisting` 노드의 유지 기간에 따른 변화\n",
    "- 유지 기간과 평가 값의 관계:\n",
    "  - `persisting` 노드의 유지 기간(streak_count)이 길어질수록 precision, freshness, satisfaction 점수가 전반적으로 감소하는 경향을 보임\n",
    "  - 특히, 4일 이상 유지된 경우 평가 값이 급격히 감소했습니다. 이는 사용자가 동일한 콘텐츠가 지속적으로 노출되는 것에 대한 피로감이 누적 되었을 수도..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 추가 조사"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 상관 관계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "freshness와 satisfaction 사이의 상관 관계: 0.966056 으로 매우 높음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[metric_cols_adjusted].corr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 콘텐츠 유형과 평가 지표의 관계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. 높은 평가를 받은 카테고리:\n",
    "- 1.4.1. 국방 정책: precision, freshness, satisfaction 모두에서 높은 점수\n",
    "- 5.9. 바이오테크놀로지: 모든 지표에서 높은 점수를 기록\n",
    "- 2.3. 부동산 및 2.2. 증권/주식: 경제 관련 카테고리에서도 전반적으로 높은 평가를 받았습니다. 이는 경제 정보에 대한 사용자 관심이 높음을 의미\n",
    "\n",
    "2. 낮은 평가를 받은 카테고리:\n",
    "- 10.2. 기상이슈, 8.1. 국내 야구: 이들 카테고리는 모든 평가 지표에서 낮은 점수, 이 주제에 대한 관심도가 낮을 수 있음을 시사\n",
    "- 7.3. 음악,  7.4. 스타/연예인: 엔터테인먼트 관련 카테고리에서도 상대적으로 낮은 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the averages of precision, freshness, and satisfaction based on the category\n",
    "category_averages = df.groupby('category')[metric_cols_adjusted].mean()\n",
    "\n",
    "# relative_category_averages = category_averages - global_averages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_averages.sort_values(by=metric_cols_adjusted, ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_averages.sort_values(by=metric_cols_adjusted, ascending=False).tail(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
